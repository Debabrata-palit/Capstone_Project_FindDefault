# -*- coding: utf-8 -*-
"""CC_FindDefault.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/187w_cXnvkkHC-vraTM3JKOEJDNwcyCL3

# Credit Card Fraud Detection Capstone Project

## Problem Statement

The dataset contains transactions made by credit cards in September 2013 by European cardholders. This dataset presents transactions that occurred in two days, where we have **492 frauds out of 284,807 transactions**. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.

**We have to build a classification model to predict whether a transaction is fraudulent or not.**

## Import basic libraries and read data
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

import warnings
warnings.filterwarnings("ignore")

df = pd.read_csv('creditcard.csv')

df.head()

"""**Note:** In *'Class'* column 0 denotes *not fraud* and 1 denotes *fraud*.

## Understanding the data
"""

df.shape

df.columns

df.info()

df.describe()

"""## Missing Value Analysis"""

df.isnull().sum()

"""## Exploratory Data Analysis"""

df_corr = df.corr()
df_corr

plt.figure(figsize=(30,20))
sns.heatmap(df_corr, annot=True)
plt.show()

sns.histplot(df['Class'])
plt.yscale('log')
plt.savefig('class_histogram.png')

df['Class'].value_counts()

#find percentage of fraud/non_fraud records
fraud_percentage = (df.groupby('Class')['Class'].count() / df['Class'].count()) * 100

plt.figure(figsize=(8, 6))
plt.pie(fraud_percentage, labels=['Non-Fraud', 'Fraud'], autopct='%0.3f%%', colors=['#66b3ff','red'])
plt.title('Percentage of Fraud and Non-Fraud Records')
plt.axis('equal')
plt.show()

"""- So, approx. 99.827% of records are non_fraud whereas 0.173% are fraud."""

imb_ratio = round(df['Class'].value_counts()[1]/df['Class'].value_counts()[0] * 100,3)
print(f'The ratio of imbalance: {imb_ratio}%')

"""- The dataset is highly imbalanced with a very low percentage of fraudulent transactions."""

amt_byclass = df.groupby('Class')['Amount'].sum()
amt_byclass

"""- We can see fraud amount is 60127.97"""

f, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(10,4))

ax1.hist(df.Time[df.Class == 1], bins = 50, edgecolor='white')
ax1.set_title('Fraud')

ax2.hist(df.Time[df.Class == 0], bins = 50, edgecolor='white')
ax2.set_title('Non Fraud')

plt.xlabel('Time')
plt.ylabel('Number of Transactions')
plt.show()

timedelta = pd.to_timedelta(df['Time'], unit='s')

df['Time_Day'] = (timedelta.dt.components.days).astype(int)
df['Time_Hr'] = (timedelta.dt.components.hours).astype(int)
df['Time_Min'] = (timedelta.dt.components.minutes).astype(int)

plt.figure(figsize=(10,5))
sns.distplot(df[df['Class'] == 0]["Time_Day"], color='#66b3ff')
sns.distplot(df[df['Class'] == 1]["Time_Day"], color='red')
plt.title('Fraud Vs Non-Fraud Transactions by Day')
plt.show()

plt.figure(figsize=(10,5))
sns.distplot(df[df['Class'] == 0]["Time_Hr"], color='#66b3ff')
sns.distplot(df[df['Class'] == 1]["Time_Hr"], color='red')
plt.title('Fraud Vs Non-Fraud Transactions by Hour')
plt.show()

f, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(10,4))

ax1.hist(df.Amount[df.Class == 1], bins = 50)
ax1.set_title('Fraud')

ax2.hist(df.Amount[df.Class == 0], bins = 50, edgecolor='white')
ax2.set_title('Non-Fraud')

plt.xlabel('Amount')
plt.ylabel('Number of Transactions')
plt.yscale('log')
plt.show()

"""## Splitting the data into train & test data"""

# Day/Mins are unnecessary here as these are not time series data, we will keep only the Time_Hr column
df.drop(['Time', 'Time_Day', 'Time_Min'], axis = 1, inplace= True)

x = df.drop(['Class'], axis=1)
y = df['Class']

from sklearn.preprocessing import PowerTransformer

pt = PowerTransformer()
x_scaled = pt.fit_transform(x)

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x_scaled, y, test_size = 0.2, random_state=12)

x_train.shape, x_test.shape, y_train.shape, y_test.shape

"""## Model Evaluation"""

from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
import xgboost as xgb
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score

"""**Logistic Regression**"""

lr = LogisticRegression(random_state = 12)

lr.fit(x_train, y_train)
lr_pred_test = lr.predict(x_test)

cl_report_lr_test = classification_report(y_test, lr_pred_test, target_names = ['Non Fraud', 'Fraud'])

print("Logistic Regression Classification Report:")
print(cl_report_lr_test)

"""- The model performs well in terms of overall accuracy. However, the fraud detection aspect can be improved, especially in terms of recall.


"""

cm = confusion_matrix(y_test, lr_pred_test)
labels = ['No Fraud', 'Fraud']
sns.heatmap(cm, annot=True, fmt='d', xticklabels=labels, yticklabels=labels)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix for Logistic Regression')
plt.show()

"""**KNN**"""

knn = KNeighborsClassifier(n_neighbors=2)

knn.fit(x_train, y_train)
knn_pred_test = knn.predict(x_test)

cl_report_knn_test = classification_report(y_test, knn_pred_test, target_names = ['Non Fraud', 'Fraud'])

print("KNN Classification Report:")
print(cl_report_knn_test)

"""- The model performs well in terms of overall accuracy. However, the fraud detection aspect can be improved, especially in terms of recall."""

cm = confusion_matrix(y_test, knn_pred_test)
labels = ['No Fraud', 'Fraud']
sns.heatmap(cm, annot=True, fmt='d', xticklabels=labels, yticklabels=labels)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix for KNN')
plt.show()

"""**XGBoosting**"""

xgb_model = xgb.XGBClassifier(random_state = 12)

xgb_model.fit(x_train, y_train)
xgb_pred_test = xgb_model.predict(x_test)

cl_report_xgb_test = classification_report(y_test, xgb_pred_test, target_names = ['Non Fraud', 'Fraud'])

print("XGBoost Classification Report:")
print(cl_report_xgb_test)

"""- The model performs well in terms of overall accuracy. However, the fraud detection aspect can be improved, especially in terms of recall."""

cm = confusion_matrix(y_test, xgb_pred_test)
labels = ['No Fraud', 'Fraud']
sns.heatmap(cm, annot=True, fmt='d', xticklabels=labels, yticklabels=labels)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix for XGBoosting')
plt.show()

"""### ROC Curve"""

lr_probs = lr.predict_proba(x_test)[:, 1]
knn_probs = knn.predict_proba(x_test)[:, 1]
xgb_probs = xgb_model.predict_proba(x_test)[:, 1]

lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)
knn_fpr, knn_tpr, _ = roc_curve(y_test, knn_probs)
xgb_fpr, xgb_tpr, _ = roc_curve(y_test, xgb_probs)

lr_auc = roc_auc_score(y_test, lr_probs)
knn_auc = roc_auc_score(y_test, knn_probs)
xgb_auc = roc_auc_score(y_test, xgb_probs)

plt.figure(figsize=(10, 6))
plt.plot(lr_fpr, lr_tpr, label=f'Logistic Regression (AUC = {lr_auc:.3f})')
plt.plot(knn_fpr, knn_tpr, label=f'KNN (AUC = {knn_auc:.3f})')
plt.plot(xgb_fpr, xgb_tpr, label=f'XGBoost (AUC = {xgb_auc:.3f})')
plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend(loc='lower right')
plt.grid(True)
plt.show()

"""- Based on the classification reports and AUC scores, we can conclude that `Logistic Regression` and `XGBoost` are the best performing models for this problem. Both models have high overall accuracy and good fraud detection capabilities, as evidenced by their high recall scores. `KNN`, on the other hand, performs slightly worse in terms of fraud detection, but still achieves a decent overall accuracy.

- In terms of **AUC scores**, `Logistic Regression` has the highest score (*0.989*), followed by `XGBoost` (*0.981*) and `KNN` (*0.925*). This indicates that `Logistic Regression` and `XGBoost` are better at distinguishing between *fraudulent* and *non-fraudulent* transactions compared to `KNN`.

- Overall, based on the results obtained, we would recommend using either `Logistic Regression` or `XGBoost` for this problem. The choice between the two models can be further refined based on additional factors such as computational resources and desired interpretability.

## Handle Imbalanced Data
"""

from imblearn.over_sampling import RandomOverSampler
ros = RandomOverSampler(random_state=0)
x_train_oversampled, y_train_oversampled = ros.fit_resample(x_train, y_train)

lr_oversampled = lr
lr_oversampled.fit(x_train_oversampled, y_train_oversampled)
lr_pred_oversampled = lr_oversampled.predict(x_test)

print("Logistic Regression Classification Report for Oversampled Data:")
print(classification_report(y_test, lr_pred_oversampled, target_names = ['Non Fraud', 'Fraud']))

xgb_oversampled = xgb_model
xgb_oversampled.fit(x_train_oversampled, y_train_oversampled)
xgb_pred_oversampled = xgb_oversampled.predict(x_test)

print("XGBoosting Classification Report for Oversampled Data:")
print(classification_report(y_test, xgb_pred_oversampled, target_names = ['Non Fraud', 'Fraud']))

from imblearn.under_sampling import RandomUnderSampler
rus = RandomUnderSampler(random_state=0)
x_train_undersampled, y_train_undersampled = rus.fit_resample(x_train, y_train)

lr_undersampled = lr
lr_undersampled.fit(x_train_undersampled, y_train_undersampled)
lr_pred_undersampled = lr_undersampled.predict(x_test)

print("Logistic Regression Classification Report for Undersampled Data:")
print(classification_report(y_test, lr_pred_undersampled, target_names = ['Non Fraud', 'Fraud']))

xgb_undersampled = xgb_model
xgb_undersampled.fit(x_train_undersampled, y_train_undersampled)
xgb_pred_undersampled = xgb_undersampled.predict(x_test)

print("XGBoosting Classification Report for Undersampled Data:")
print(classification_report(y_test, xgb_pred_undersampled, target_names = ['Non Fraud', 'Fraud']))

from imblearn.over_sampling import SMOTE
smote = SMOTE(random_state=0)
x_train_smote, y_train_smote = smote.fit_resample(x_train, y_train)

lr_smote = lr
lr_smote.fit(x_train_smote, y_train_smote)
lr_pred_smote = lr_smote.predict(x_test)

print("Logistic Regression Classification Report for SMOTE Data:")
print(classification_report(y_test, lr_pred_smote, target_names = ['Non Fraud', 'Fraud']))

xgb_smote = xgb_model
xgb_smote.fit(x_train_smote, y_train_smote)
xgb_pred_smote = xgb_smote.predict(x_test)

print("XGBoosting Classification Report for SMOTE Data:")
print(classification_report(y_test, xgb_pred_smote, target_names = ['Non Fraud', 'Fraud']))

"""> Logistic Regression:

**Oversampled Data:** The precision for detecting fraud is very low (0.05), indicating a high rate of false positives. However, recall is high (0.94), meaning that the model identifies a high proportion of actual fraud cases. The overall F1-score is low due to the imbalanced precision and recall.  
**Undersampled Data:** Similar to oversampled data, the precision for fraud detection is low (0.05), with a high recall (0.94). The F1-score is also low.  
**SMOTE Data:** Precision remains low for fraud detection (0.05), but recall decreases slightly compared to oversampled and undersampled data. The F1-score remains low due to the imbalanced precision and recall.

> XGBoost:

**Oversampled Data:** The precision for fraud detection is higher (0.95) compared to logistic regression, with a relatively high recall (0.81). The F1-score is also higher, indicating a better balance between precision and recall compared to logistic regression.  
**Undersampled Data:** Precision for fraud detection remains low (0.04), similar to logistic regression. However, recall is higher (0.92), resulting in a slightly higher F1-score compared to logistic regression.  
**SMOTE Data:** Precision for fraud detection is slightly lower compared to oversampled data (0.88), but recall is also slightly higher (0.85). The F1-score remains relatively high, indicating a good balance between precision and recall.

> Summary:

`XGBoost` performs best with the oversampling technique based on the provided classification reports. In the oversampled data scenario, `XGBoost` achieved the highest precision, recall, and F1-score for detecting fraud compared to undersampled and SMOTE data.

## Hyperparameter tuning
"""

from sklearn.model_selection import StratifiedKFold

kfold = StratifiedKFold(n_splits=5, random_state=12, shuffle=True)

cl_report_list = []
for train_index, test_index in kfold.split(x_train_oversampled, y_train_oversampled):
    x_train_fold, x_test_fold = x_train_oversampled[train_index], x_train_oversampled[test_index]
    y_train_fold, y_test_fold = y_train_oversampled[train_index], y_train_oversampled[test_index]
    xgb_model.fit(x_train_fold, y_train_fold)
    y_pred_fold = xgb_model.predict(x_test_fold)
    cl_report_list.append(classification_report(y_test_fold, y_pred_fold, target_names = ['Non Fraud', 'Fraud']))

print("XGBoost Classification Report with Stratified KFold:\n")
for report in cl_report_list:
  print(report)

"""- Based on the results obtained from the classification reports, we can conclude that using `XGBoost` with **oversampled data** and **stratified k-fold cross-validation** provides the best performance for detecting fraudulent transactions. This approach consistently achieves high precision, recall, and F1-score across multiple folds, indicating its robustness and effectiveness in handling imbalanced data and making accurate predictions.

## Overall Conclusion:

Looking at above results it seems `XGBoost` model with **Random Oversampling** with **StratifiedKFold CV** has provided best results. So we can try to tune the hyperparameters of this model to get best results
"""